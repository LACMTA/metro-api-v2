{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Updating Static GTFS Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import calendar\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import timeit\n",
    "# from sqlalchemy.orm import Session,sessionmaker\n",
    "# Using SQLAlchemy to connect to the Database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy import create_engine,MetaData,event\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import secrets as Config\n",
    "\n",
    "# from .utils.log_helper import *\n",
    "\n",
    "from secrets import *\n",
    "engine = create_engine(Config.URI, echo=False)\n",
    "\n",
    "Session = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "session = Session()\n",
    "target_schema = \"metro_api_dev\"\n",
    "Base = declarative_base(metadata=MetaData(schema=target_schema))\n",
    "\n",
    "def get_db():\n",
    "    db = Session()\n",
    "    try:\n",
    "        print('Connected to the database')\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "list_of_gtfs_static_files = [\"stop_times\",\"trips\",\"stops\"]\n",
    "# list_of_gtfs_static_files = [\"calendar_dates\",\"calendar\",\"routes\",\"shapes\",\"stop_times\",\"stops\",\"trips\"]\n",
    "\n",
    "debug = True\n",
    "print('Finished loading libraries')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading the data and creating the `stop_times` and `trips` data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_file_exists(gtfs_type,file):\n",
    "    file_path = \"../appdata/gtfs-static/\"+gtfs_type+\"/\" + file + '.txt'\n",
    "    if Path(file_path).is_file():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def update_gtfs_static_files():\n",
    "    print('[Debug:{}]'.format(debug))\n",
    "    process_start = timeit.default_timer()\n",
    "    global stop_times_df\n",
    "    global trips_df\n",
    "    global calendar_dates_df\n",
    "    global calendar_df\n",
    "    global stops_df\n",
    "    for file in list_of_gtfs_static_files:\n",
    "        if check_if_file_exists(\"gtfs_bus\",file) == True and check_if_file_exists(\"gtfs_rail\",file) == True:\n",
    "            print('Updating '+file)\n",
    "            bus_file_path = \"../appdata/gtfs-static/gtfs_bus/\" + file + '.txt'\n",
    "            rail_file_path = \"../appdata/gtfs-static/gtfs_rail/\" + file + '.txt'\n",
    "            temp_df_bus = pd.read_csv(bus_file_path)\n",
    "            temp_df_bus['agency_id'] = 'LACMTA'\n",
    "            temp_df_rail = pd.read_csv(rail_file_path)\n",
    "            temp_df_rail['agency_id'] = 'LACMTA_Rail'\n",
    "            if file == \"stops\":\n",
    "                stops_df = update_stops_seperately(file)\n",
    "            \n",
    "            elif file == \"shapes\":\n",
    "                temp_gdf_bus = gpd.GeoDataFrame(temp_df_bus, geometry=gpd.points_from_xy(temp_df_bus.shape_pt_lon, temp_df_bus.shape_pt_lat))   \n",
    "                temp_gdf_rail = gpd.GeoDataFrame(temp_df_rail, geometry=gpd.points_from_xy(temp_df_rail.shape_pt_lon, temp_df_rail.shape_pt_lat))\n",
    "                shapes_combined_gdf = gpd.GeoDataFrame(pd.concat([temp_gdf_bus, temp_gdf_rail],ignore_index=True),geometry='geometry')\n",
    "                shapes_combined_gdf['shape_id_sequence'] = shapes_combined_gdf['shape_id'] +'_' +str(shapes_combined_gdf['shape_pt_sequence'])\n",
    "                shapes_combined_gdf.crs = {'init': 'epsg:4326'}\n",
    "                if debug == False:\n",
    "                    shapes_combined_gdf.to_postgis(file,engine,index=False,if_exists=\"replace\",schema=target_schema)\n",
    "\n",
    "            else:\n",
    "                combined_temp_df = pd.concat([temp_df_bus, temp_df_rail])\n",
    "                if file == \"stop_times\":\n",
    "                    stop_times_df = combined_temp_df\n",
    "                if file == \"trips\":\n",
    "                    trips_df = combined_temp_df\n",
    "                if file == \"calendar_dates\":\n",
    "                    calendar_dates_df = combined_temp_df\n",
    "                if file == \"calendar\":\n",
    "                    calendar_df = combined_temp_df\n",
    "                if debug == False:\n",
    "                    combined_temp_df.to_sql(file,engine,index=False,if_exists=\"replace\",schema=target_schema)\n",
    "            process_end = timeit.default_timer()\n",
    "            print('Updating took {} seconds'.format(process_end - process_start))\n",
    "\n",
    "\n",
    "def update_stops_seperately(file):\n",
    "    bus_file_path = \"../appdata/gtfs-static/gtfs_bus/\" + file + '.txt'\n",
    "    temp_df_bus = pd.read_csv(bus_file_path)\n",
    "    # temp_df_bus['geometry'] = [Point(xy) for xy in zip(temp_df_bus.stop_lon, temp_df_bus.stop_lat)] \n",
    "    temp_df_bus['agency_id'] = 'LACMTA'\n",
    "    temp_gdf_bus_stops = gpd.GeoDataFrame(temp_df_bus,geometry=gpd.points_from_xy(temp_df_bus.stop_lon, temp_df_bus.stop_lat))\n",
    "    temp_gdf_bus_stops.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    rail_file_path = \"../appdata/gtfs-static/gtfs_rail/\" + file + '.txt'\n",
    "    temp_df_rail = pd.read_csv(rail_file_path)\n",
    "    # temp_df_rail['geometry'] = [Point(xy) for xy in zip(temp_df_rail.stop_lon, temp_df_rail.stop_lat)] \n",
    "    temp_df_rail['agency_id'] = 'LACMTA_Rail'\n",
    "    temp_gdf_bus_stops['stop_id'] = temp_gdf_bus_stops['stop_id'].astype('str')\n",
    "    temp_gdf_bus_stops['stop_code'] = temp_gdf_bus_stops['stop_code'].astype('str')\n",
    "    temp_gdf_bus_stops['parent_station'] = temp_gdf_bus_stops['parent_station'].astype('str')\n",
    "    temp_gdf_bus_stops['tpis_name'] = temp_gdf_bus_stops['tpis_name'].astype('str')\n",
    "\n",
    "    temp_gdf_rail_stops = gpd.GeoDataFrame(temp_df_rail,geometry=gpd.points_from_xy(temp_df_rail.stop_lon, temp_df_rail.stop_lat))\n",
    "    temp_gdf_rail_stops.set_crs(epsg=4326, inplace=True)\n",
    "    temp_gdf_rail_stops['stop_id'] = temp_gdf_rail_stops['stop_id'].astype('str')\n",
    "    temp_gdf_rail_stops['stop_code'] = temp_gdf_rail_stops['stop_code'].astype('str')\n",
    "    temp_gdf_rail_stops['parent_station'] = temp_gdf_rail_stops['parent_station'].astype('str')\n",
    "    temp_gdf_rail_stops['tpis_name'] = temp_gdf_rail_stops['tpis_name'].astype('str')\n",
    "    if debug == False:\n",
    "        temp_gdf_rail_stops.to_postgis(\"stops\",engine,schema=target_schema,if_exists=\"replace\",index=False)\n",
    "        temp_gdf_bus_stops.to_postgis(\"stops\",engine,schema=target_schema,if_exists=\"append\",index=False)\n",
    "    return pd.concat([temp_gdf_bus_stops,temp_gdf_rail_stops])\n",
    "    \n",
    "update_gtfs_static_files()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating the list of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_type_from_service_id(row):\n",
    "    # print('Getting day type from service id')\n",
    "    cleaned_row = str(row).lower()\n",
    "    if 'weekday' in cleaned_row:\n",
    "        return 'weekday'\n",
    "    elif 'saturday' in cleaned_row:\n",
    "        return 'saturday'\n",
    "    elif 'sunday' in cleaned_row:\n",
    "        return 'sunday'\n",
    "\n",
    "def get_day_type_from_trip_id(trip_id):\n",
    "    # print('Getting day type from trip id')\n",
    "   this_service_id = trips_df.loc[trips_df['trip_id'] == trip_id, 'service_id'].iloc[0]\n",
    "   return get_day_type_from_service_id(this_service_id)\n",
    "\n",
    "def create_list_of_trips(trips,stop_times):\n",
    "    print('Creating list of trips')\n",
    "    global trips_list_df\n",
    "    # stop_times['day_type'] = stop_times['trip_id_event'].map(get_day_type_from_service_id)\n",
    "    # stop_times['day_type'] = stop_times['day_type'].fillna(stop_times['trip_id'].map(get_day_type_from_trip_id))\n",
    "    trips_list_df = stop_times.groupby('trip_id')['stop_sequence'].max().sort_values(ascending=False).reset_index()\n",
    "    trips_list_df = trips_list_df.merge(stop_times[['trip_id','stop_id','stop_sequence','route_code']], on=['trip_id','stop_sequence'])\n",
    "    summarized_trips_df = trips[[\"route_id\",\"trip_id\",\"direction_id\",\"service_id\",\"agency_id\"]]\n",
    "    summarized_trips_df['day_type'] = summarized_trips_df['service_id'].map(get_day_type_from_service_id)\n",
    "    trips_list_df = trips_list_df.merge(summarized_trips_df, on='trip_id').drop_duplicates(subset=['route_id','day_type','direction_id'])\n",
    "    trips_list_df.to_csv('trips_list_df.csv')\n",
    "\n",
    "\n",
    "create_list_of_trips(trips_df,stop_times_df)\n",
    "# print(trips_list_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Optional - Check `trip_id` results\n",
    "\n",
    "Results from this check can be cross-referenced with the **POSTgreSQL database** to see if the `max_sequence` are accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trip_id_times(trip_id):\n",
    "    print('Checking trip id times')\n",
    "    this_trips_df = stop_times_df.loc[stop_times_df['trip_id'] == trip_id]\n",
    "    return this_trips_df\n",
    "\n",
    "\n",
    "def check_route_id_trips_list(route_id):\n",
    "    print('Checking route id stop times')\n",
    "    this_trips_df = trips_list_df.loc[trips_list_df['route_id'] == route_id]\n",
    "    return this_trips_df\n",
    "\n",
    "check_trip_id_times('54093732-SoFi_Stadium_Express_1900')\n",
    "check_trip_id_times('10169001481613-DEC22')\n",
    "\n",
    "check_route_id_trips_list('169-13167')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Getting the stop times data\n",
    "\n",
    "trips_list_df\n",
    "- route_id\n",
    "- trip_id\n",
    "- stop_sequence\n",
    "\n",
    "for each row in trips_list_df, apply a function\n",
    "inputs: route_id, trip_id\n",
    "\n",
    "function:\n",
    "get rows from stop_times that match the trip_id\n",
    "get stop_id column from these rows\n",
    "add the route_id as a column\n",
    "\n",
    "\n",
    "resulting dataframe:\n",
    "| route_id | stop_id |\n",
    "| -------- | ------- |\n",
    "| 2 | 100 |\n",
    "| 2 | 101 |\n",
    "| 2 | 102 |\n",
    "| 4 | 104 |\n",
    "\n",
    "vs\n",
    "\n",
    "| route_id | stop_id |\n",
    "| -------- | ------- |\n",
    "| 2 | [100,101,102] |\n",
    "| 4 | [104] |\n",
    "\n",
    "\n",
    "Need to also consider:\n",
    "- direction\n",
    "- day of week\n",
    "- lower priority: active service (calendar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stop_times_dataframe = pd.DataFrame()\n",
    "\n",
    "df_to_combine = []\n",
    "\n",
    "def encode_lat_lon_to_geojson(lat,lon):\n",
    "    this_geojson = {\n",
    "        \"type\":\"Feature\",\n",
    "        \"geometry\":{\n",
    "            \"type\":\"Point\",\n",
    "            \"coordinates\": [lon,lat]\n",
    "        }\n",
    "    }\n",
    "    return this_geojson\n",
    "\n",
    "\n",
    "def get_stops_data_based_on_stop_id(stop_id):\n",
    "    # print('Getting stops data based on stop id')\n",
    "    this_stops_df = stops_df.loc[stops_df['stop_id'] == str(stop_id)]\n",
    "    # print(this_stops_df[['stop_name','stop_lat','stop_lon']])\n",
    "    # new_object = this_stops_df[['stop_name','stop_lat','stop_lon']].to_dict('records')\n",
    "    new_object = encode_lat_lon_to_geojson(this_stops_df['stop_lat'].values[0],this_stops_df['stop_lon'].values[0])\n",
    "    # print('stop_id',stop_id)\n",
    "    return new_object\n",
    "\n",
    "\n",
    "def get_stop_times_for_trip_id(this_row):\n",
    "    this_trips_df = stop_times_df.loc[stop_times_df['trip_id'] == this_row.trip_id]\n",
    "    this_trips_df['route_id'] = this_row.route_id\n",
    "    # this_trips_df['service_id'] = this_row.service_id\n",
    "    this_trips_df['direction_id'] = this_row.direction_id\n",
    "    this_trips_df['day_type'] = this_row.day_type\n",
    "    this_trips_df['geojson'] = this_trips_df.apply(lambda x: get_stops_data_based_on_stop_id(x.stop_id),axis=1)\n",
    "    this_trips_df['stop_name'] = this_trips_df.apply(lambda x: stops_df.loc[stops_df['stop_id'] == str(x.stop_id)]['stop_name'].values[0],axis=1)\n",
    "    # simplified_df = this_trips_df[['route_id','stop_id','service_id','day_type','direction_id','stop_name','coordinates']]\n",
    "    simplified_df = this_trips_df[['route_id','route_code','stop_id','day_type','stop_sequence','direction_id','stop_name','geojson','agency_id']]\n",
    "    \n",
    "    df_to_combine.append(simplified_df)\n",
    "    return simplified_df\n",
    "\n",
    "# hi_nina_df = get_stop_times_for_trip_id(trips_list_df.iloc[103])\n",
    "# hi_nina_df.to_csv('hi_nina_df.csv')\n",
    "\n",
    "#### Running the `get_stop_times_for_trip_id`` function on the entire dataframe\n",
    "trips_list_df.apply(lambda row: get_stop_times_for_trip_id(row), axis=1)\n",
    "# trips_list_df.map(get_stop_times_for_trip_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times_by_route_df = pd.concat(df_to_combine)\n",
    "stop_times_by_route_df.to_csv('stop_times_by_route_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sofi check\n",
    "sofi_df = stop_times_by_route_df.loc[stop_times_by_route_df['route_id'] == 'SOFI']\n",
    "sofi_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Getting the `stop_times` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stop_times_array = [] \n",
    "import json\n",
    "\n",
    "def get_stop_times_from_stop_id(this_row):\n",
    "    # print('Getting stop times for stop id')\n",
    "    trips_by_route_df = trips_df.loc[trips_df['route_id'] == this_row.route_id]\n",
    "    \n",
    "    stop_times_by_trip_df = stop_times_df[stop_times_df['trip_id'].isin(trips_by_route_df['trip_id'])]\n",
    "\n",
    "    # get the stop times for this stop id\n",
    "    this_stops_df = stop_times_by_trip_df.loc[stop_times_by_trip_df['stop_id'] == this_row.stop_id]\n",
    "    this_stops_df = this_stops_df.sort_values(by=['departure_time'],ascending=True)\n",
    "    # simplified_this_stops_df = simplified_this_stops_df.to_json(orient='records')\n",
    "\n",
    "    departure_times_array = this_stops_df['departure_time'].values.tolist()\n",
    "    # to check:\n",
    "    # print(simplified_this_stops_df)\n",
    "\n",
    "    # combined_stop_times_array.append(simplified_this_stops_df)\n",
    "    return departure_times_array\n",
    "\n",
    "#### for checking purposes\n",
    "# stop_times_by_route_df['departure_times'] = get_stop_times_from_stop_id(stop_times_by_route_df.iloc[7584])\n",
    "# get_stop_times_from_stop_id(stop_times_by_route_df.iloc[7585])\n",
    "# print(stop_times_by_route_df)\n",
    "\n",
    "# test_df_that_contains_another_df_in_column = pd.DataFrame({'route_id': ['SOFI'], 'departure_df': [this_df]})\n",
    "# test_df_that_contains_another_df_in_column['test'] = 'hi' \n",
    "# test_df_that_contains_another_df_in_column['departure_df'] = get_stop_times_from_stop_id(stop_times_by_route_df.iloc[3])\n",
    "# stop_times_by_route_df.apply(lambda x: get_stop_times_from_stop_id(x), axis=1).groupby(['route_id','stop_id']).apply(lambda x: pd.concat(x)).to_dict('records').reset_index().to_json(orient='records')\n",
    "# test_df_that_contains_another_df_in_column\n",
    "\n",
    "\n",
    "# stop_times_by_route_df.apply(lambda x: get_stop_times_from_stop_id(x), axis=1)\n",
    "# stop_times_by_route_df.apply(lambda x: get_stop_times_from_stop_id(x['route_id'],x['stop_id']), axis=1)\n",
    "\n",
    "\n",
    "#### real code here\n",
    "stop_times_by_route_df['departure_times'] = stop_times_by_route_df.apply(lambda row: get_stop_times_from_stop_id(row),axis=1)\n",
    "\n",
    "# stop_times_by_route_df.map(get_stop_times_from_stop_id)\n",
    "# combined_simplified_this_stops_df = pd.concat(combined_stop_times_array)\n",
    "# combined_simplified_this_stops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.concat(combined_stop_times_array)\n",
    "from shapely.geometry import Point\n",
    "def get_lat_long_from_coordinates(geojson):\n",
    "    this_geojson_geom = geojson['geometry']\n",
    "    return Point(this_geojson_geom['coordinates'][0], this_geojson_geom['coordinates'][1])\n",
    "\n",
    "stop_times_by_route_df['route_code'].fillna(stop_times_by_route_df['route_id'], inplace=True)\n",
    "\n",
    "route_stops_geo_data_frame = gpd.GeoDataFrame(stop_times_by_route_df, geometry=stop_times_by_route_df.apply(lambda x: get_lat_long_from_coordinates(x.geojson),axis=1))\n",
    "route_stops_geo_data_frame.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# if you want to pre-process the data before saving it to the database, do it here! :)\n",
    "if debug == False:\n",
    "    # save to database\n",
    "    route_stops_geo_data_frame.to_postgis('route_stops',engine,index=False,if_exists=\"replace\",schema=target_schema)\n",
    "    # stop_times_by_route_df.to_csv('final_df.csv')\n",
    "# route_stops_geo_data_frame.to_postgis('route_stops',engine,index=False,if_exists=\"replace\",schema=target_schema)\n",
    "# stop_times_by_route_df.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "route_stops_geo_data_frame\n",
    "route_stops_geo_data_frame['route_code'].astype('str')\n",
    "\n",
    "def get_individual_route_data(target_data):\n",
    "       initial_json = (target_data.groupby(['direction_id','day_type'])\n",
    "       .apply(lambda x: x.to_dict('records'))\n",
    "       .reset_index()\n",
    "       .rename(columns={0:'data'})\n",
    "       .groupby('direction_id')['day_type','data']\n",
    "       .apply(lambda x:x.set_index('day_type')['data'].to_dict())\n",
    "       .to_json(orient='index',indent=4)\n",
    "       )\n",
    "       cleaned_json = [json.loads(initial_json)]\n",
    "       # initial_json.to_dict()\n",
    "       return cleaned_json\n",
    "\n",
    "\n",
    "def get_departure_times(route):\n",
    "       target_data = route_stops_geo_data_frame.loc[route_stops_geo_data_frame['route_code'].astype('str') == route]\n",
    "       if target_data.shape[0] > 0:\n",
    "              payload = []\n",
    "       # payload.append(target_data.apply(lambda x: get_individual_route_data(x),axis=1))\n",
    "              payload.append(get_individual_route_data(target_data))\n",
    "       \n",
    "              final_payload = [pd.json_normalize(payload).assign(route_code=route).to_dict('records')]\n",
    "       # final_payload = [pd.json_normalize(payload).assign(route_code=route).to_dict('records')]\n",
    "\n",
    "\n",
    "       # initial_json = (target_data.groupby(['direction_id','day_type'])['departure_times','stop_sequence','stop_name','stop_id','coordinates']\n",
    "       # .apply(lambda x: x.to_dict('r'))\n",
    "       # .reset_index(name='data')\n",
    "       # .groupby('direction_id')['day_type','data']\n",
    "       # .apply(lambda x: x.set_index('day_type')['data'].to_dict())\n",
    "       # .to_json(orient='index',indent=4)\n",
    "       # )\n",
    "       # cleaned_json = json.loads(initial_json)\n",
    "       # initial_json.to_dict()\n",
    "              return final_payload\n",
    "       else:\n",
    "              return None\n",
    "final_df = pd.DataFrame()\n",
    "route_code_df = pd.DataFrame({'route_code':route_stops_geo_data_frame['route_code'].unique().astype('str')})\n",
    "route_id_df = pd.DataFrame({'route_id':route_stops_geo_data_frame['route_id'].unique().astype('str')})\n",
    "final_df = pd.concat([route_code_df,route_id_df],ignore_index=True, axis=1)\n",
    "final_df.columns = ['route_code','route_id']\n",
    "# final_df['route_id'].fillna(final_df['route_code'], inplace=True)\n",
    "\n",
    "\n",
    "# final_df['agency_id'] = route_stops_geo_data_frame[''].unique()\n",
    "# final_df['payload'] = final_df['route_code'].apply(lambda x: get_departure_times(x))\n",
    "# print(final_df)\n",
    "# final_df\n",
    "# final_df.to_postgis('route_stops_grouped',engine,index=False,if_exists=\"replace\",schema=target_schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_stops_geo_data_frame\n",
    "route_stops_geo_data_frame['route_code'].astype('str')\n",
    "\n",
    "def get_individual_route_data(target_data):\n",
    "       target_data['day_type'] = target_data['day_type'].astype('str')\n",
    "       initial_json = (target_data.groupby(['direction_id','day_type'])\n",
    "       .apply(lambda x: x.to_dict('records'))\n",
    "       .reset_index()\n",
    "       .rename(columns={0:'data'})\n",
    "       .groupby('direction_id')['day_type','data']\n",
    "       .apply(lambda x:x.set_index('day_type')['data'].to_dict())\n",
    "       .to_json(orient='index',indent=4)\n",
    "       )\n",
    "       cleaned_json = [json.loads(initial_json)]       \n",
    "       # initial_json.to_dict()\n",
    "       return cleaned_json\n",
    "\n",
    "def get_departure_times(route):\n",
    "    target_data = route_stops_geo_data_frame.loc[route_stops_geo_data_frame['route_code'].astype('str') == route]\n",
    "    if target_data.shape[0] > 0:\n",
    "        payload = []\n",
    "        payload.append(get_individual_route_data(target_data))\n",
    "        final_payload = [pd.json_normalize(payload).assign(route_code=route).to_dict('records')]\n",
    "        return final_payload\n",
    "    del target_data\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "route_code_df = pd.DataFrame({'route_code':route_stops_geo_data_frame['route_code'].unique().astype('str')})\n",
    "route_id_df = pd.DataFrame({'route_id':route_stops_geo_data_frame['route_id'].unique().astype('str')})\n",
    "final_df = pd.concat([route_code_df,route_id_df],ignore_index=True, axis=1)\n",
    "final_df.columns = ['route_code','route_id']\n",
    "final_df['payload'] = final_df['route_code'].apply(lambda x: get_departure_times(x))\n",
    "final_df['payload'] = final_df['payload'].astype('str')\n",
    "final_df['payload'] = final_df['payload'].str.replace('0.weekday','weekday')\n",
    "final_df['payload'] = final_df['payload'].str.replace('0.saturday','saturday')\n",
    "final_df['payload'] = final_df['payload'].str.replace('0.sunday','sunday')\n",
    "final_df['payload'] = final_df['payload'].str.replace('0.nan','none')\n",
    "final_df['payload'] = final_df['payload'].str.replace('1.weekday','weekday')\n",
    "final_df['payload'] = final_df['payload'].str.replace('1.saturday','saturday')\n",
    "final_df['payload'] = final_df['payload'].str.replace('1.sunday','sunday')\n",
    "final_df['payload'] = final_df['payload'].str.replace('1.nan','none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- for each `route_id`, we have a list of `trip_ids` -->\n",
    "\n",
    "`trips_list_df `-> max_sequence, route_id, trip_id\n",
    "\n",
    "`trips_df` -> trips table\n",
    "\n",
    "`stop_times_df` -> stop_times table\n",
    "\n",
    "`stop_times_by_route_df` -> stop_times based on `trip_id` with max_sequence for each `route_id`: route_id, stop_id\n",
    "\n",
    "apply this function to each row in `stop_times_by_route_df`:\n",
    "(given a `route_id` and `stop_id`)\n",
    "\n",
    "a) new `trips_by_route_df` = filter `trips_df` by `route_id`\n",
    "\n",
    "new `stop_times_by_trip_df` = filter `stop_times_df` by `trip_ids` within `trips_by_route_df`\n",
    "\n",
    "new `results_df` = `stop_times_by_trip_df` columns: `departure_times`, `stop_id`\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated example: 1/26/2023\n",
    "```json\n",
    "{\n",
    "  route_id: '',\n",
    "  direction_0: \n",
    "  {\n",
    "    weekday:\n",
    "    [\n",
    "      {\n",
    "        stop_id: '',\n",
    "        stop_name: '',\n",
    "        stop_sequence: '',\n",
    "        coordinate: '',\n",
    "        departure_times: \n",
    "        [\n",
    "          {\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          },{\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          },{\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          },{\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          }\n",
    "        ]\n",
    "      },{\n",
    "        stop_id: '',\n",
    "        stop_name: '',\n",
    "        stop_sequence: '',\n",
    "        coordinate: '',\n",
    "        departure_times: \n",
    "        [\n",
    "          {\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          },{\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          },{\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          },{\n",
    "            trip_id: '',\n",
    "            departure_time: ''\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    saturday: \n",
    "    [\n",
    "      {}\n",
    "    ],\n",
    "    sunday:\n",
    "    [\n",
    "      {}\n",
    "    ]\n",
    "  },\n",
    "  direction_1: \n",
    "  {\n",
    "    weekday:\n",
    "    [\n",
    "      {}\n",
    "    ],\n",
    "    saturday: \n",
    "    [\n",
    "      {}\n",
    "    ],\n",
    "    sunday:\n",
    "    [\n",
    "      {}\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` js\n",
    "[\n",
    "  {\n",
    "    route_id: `801`,\n",
    "    stop_id: `80214`,\n",
    "    stop_name: 'Union Station - Metro Red & Purple Lines',\n",
    "    coordinate: .....,\n",
    "    stop_sequence: {\n",
    "      direction_0: {\n",
    "        weekday: 1,\n",
    "        saturday: 1,\n",
    "        sunday: 1\n",
    "      },\n",
    "      direction_1: {\n",
    "        weekday: 14\n",
    "        saturday: 14\n",
    "        sunday: 14\n",
    "      }\n",
    "    }\n",
    "    stop_times: {\n",
    "      direction_0: {\n",
    "        weekday: [\n",
    "          '05:01:00',\n",
    "          ...\n",
    "        ],\n",
    "        saturday: [\n",
    "          '05:01:00',\n",
    "          ...\n",
    "        ],\n",
    "        sunday: [\n",
    "          '05:01:00',\n",
    "          ...\n",
    "        ]\n",
    "      },\n",
    "      direction_1: {\n",
    "        weekday: [\n",
    "          '05:01:00',\n",
    "          ...\n",
    "        ],\n",
    "        saturday: [\n",
    "          '05:01:00',\n",
    "          ...\n",
    "        ],\n",
    "        sunday: [\n",
    "          '05:01:00',\n",
    "          ...\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "   ...\n",
    "  }\n",
    "]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c263e3016fdbcc18f23c6f6a65675b5fd898a6e9c804caa5b7f1b343f9ad6c95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
